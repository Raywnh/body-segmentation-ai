{"cells":[{"cell_type":"markdown","metadata":{"id":"ikl80icYlOqR"},"source":["# Segmented Body Part Enlarger"]},{"cell_type":"markdown","metadata":{"id":"2hQpKnW8_lKU"},"source":["# Install Dependencies"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34046,"status":"ok","timestamp":1714783537306,"user":{"displayName":"Ray Ho","userId":"02253827767876149996"},"user_tz":420},"id":"BtncKRCBZpK9","outputId":"27aa0380-1f9a-4ad8-8b87-aa5c53ede3e7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UKqxsYPg-rm0"},"outputs":[],"source":["!apt-get install imagemagick\n","!pip install Wand"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YBoQUaAf-285"},"outputs":[],"source":["!pip install -U torch==2.2.1 torchvision\n","!pip install git+https://github.com/facebookresearch/fvcore.git\n","import torch, torchvision\n","torch.__version__"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SViSCz-PCBE6"},"outputs":[],"source":["!git clone https://github.com/facebookresearch/detectron2 detectron2_repo\n","!pip install -e detectron2_repo"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":9757,"status":"ok","timestamp":1714783857868,"user":{"displayName":"Ray Ho","userId":"02253827767876149996"},"user_tz":420},"id":"nr4TvhvgEEbJ"},"outputs":[],"source":["# You may need to restart your runtime prior to this, to let your installation take effect\n","import detectron2\n","from detectron2.utils.logger import setup_logger\n","setup_logger()\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import cv2\n","from google.colab.patches import cv2_imshow\n","\n","from detectron2.engine import DefaultPredictor\n","from detectron2.config import get_cfg\n","from detectron2.utils.visualizer import Visualizer\n","from detectron2.data import MetadataCatalog, DatasetCatalog\n","from detectron2.checkpoint import Checkpointer\n","import os\n","import random"]},{"cell_type":"markdown","metadata":{"id":"KApzQHvzca-V"},"source":["# Run Segmentation Predictor"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"baTkXFPNj5jN","outputId":"8f373f6d-f9d6-4a03-f9dd-ffbceda33c13"},"outputs":[{"name":"stdout","output_type":"stream","text":["[05/04 00:51:22 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from /content/drive/MyDrive/ML_Stuff/model_9/model_final.pth ...\n"]}],"source":["path = \"/content/drive/MyDrive/ML_Stuff/model_9\"\n","cfg = get_cfg()\n","cfg.merge_from_file(\"./detectron2_repo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n","cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1 \n","cfg.MODEL.WEIGHTS = os.path.join(path, \"model_final.pth\")\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.4\n","cfg.MODEL.DEVICE = 'cpu'\n","predictor = DefaultPredictor(cfg)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2lUvDvcac_BG"},"outputs":[],"source":["from detectron2.utils.visualizer import ColorMode\n","\n","im = cv2.imread('test.jpg')\n","outputs = predictor(im)\n","\n","v = Visualizer(im[:, :, ::-1],\n","  scale=1.0,\n",")\n","\n","instances = outputs[\"instances\"].to(\"cpu\")\n","\n","if len(instances) > 0:\n","  highest_score_index = instances.scores.argmax()\n","  highest_score_instance = instances[highest_score_index:highest_score_index + 1]\n","  mask_res = highest_score_instance.pred_masks[0]\n","  box = highest_score_instance.pred_boxes\n","else:\n","  highest_score_instance = instances\n","  mask_res = None\n","\n","v = v.draw_instance_predictions(highest_score_instance)\n","cv2_imshow(v.get_image()[:, :, ::-1])"]},{"cell_type":"markdown","metadata":{"id":"UWe9AoSIS-lT"},"source":["Mask and ROI Preparation"]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":214,"status":"ok","timestamp":1714777887085,"user":{"displayName":"Ray Ho","userId":"02253827767876149996"},"user_tz":420},"id":"VL7zkuQhrmxb"},"outputs":[],"source":["import cv2\n","import numpy as np\n","from wand.image import Image\n","\n","mask_np = mask_res.numpy().astype(np.uint8)\n","\n","# Binary mask for layer masking later\n","mask = mask_np * 255\n","\n","# The isolated region on the real image that we want to transform\n","isolated_roi = cv2.bitwise_and(im, im, mask=mask)"]},{"cell_type":"markdown","metadata":{"id":"KywPaEuylX3x"},"source":["# Segmented Body Part Enlarging"]},{"cell_type":"markdown","metadata":{"id":"pIESSbMKaIJU"},"source":["Distortion"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"anCQIZc2vZq4"},"outputs":[],"source":["from PIL import Image, ImageFilter\n","\n","def apply_perspective_warp(image, roi_corners, transformed_corners):\n","  src_points = np.array(roi_corners, dtype=np.float32)\n","  dst_points = np.array(transformed_corners, dtype=np.float32)\n","\n","  M = cv2.getPerspectiveTransform(src_points, dst_points)\n","\n","  warped_roi = cv2.warpPerspective(image, M, (image.shape[1], image.shape[0]))\n","\n","  return warped_roi\n","\n","def get_warp_factor(bbox, img_width, img_height):\n","  h_factor = 400\n","  v_factor = 200\n","  x1, y1, x2, y2 = bbox\n","\n","  distance_to_left = x1\n","  distance_to_right = img_width - x2\n","  distance_to_top = y1\n","  distance_to_bottom = img_height - y2\n","\n","  h_stretch = h_factor * (img_width / (distance_to_left + distance_to_right))\n","  v_stretch = v_factor * (img_height / (distance_to_top + distance_to_bottom))\n","\n","  return int(h_stretch), int(v_stretch)\n","\n","x1, y1, x2, y2 = box.tensor.numpy()[0].astype('int')\n","center_x = (x1 + x2) // 2\n","center_y = (y1 + y2) // 2\n","height, width = isolated_roi.shape[:2]\n","h_stretch, v_stretch = get_warp_factor((x1, y1, x2, y2), width, height)\n","\n","print(\"Center X: \" + str(center_x) + \", Center Y: \" + str(center_y))\n","print(\"Height: \" + str(height) +\", Width: \" + str(width))\n","print(\"Top Left: \" + str(x1) + \", Top Right: \" + str(x2) + \", Bottom Left: \" + str(y1) + \", Bottom Right: \" + str(y2))\n","print(\"Horizontal Stretch: \" + str(h_stretch) + \", Vertical Stretch: \" + str(v_stretch))\n","\n","roi_corners = [(x1, y1), (x2, y1), (x2, y2), (x1, y2)]\n","transformed_corners = [(x1, y1), (x2, y1), (x2 + h_stretch, y2 + v_stretch), (x1 - h_stretch, y2 + v_stretch)]\n","\n","transformed_roi = apply_perspective_warp(isolated_roi.copy(), roi_corners, transformed_corners)\n","transformed_roi_img = Image.fromarray(transformed_roi).filter(ImageFilter.ModeFilter(size=10))\n","transformed_roi = np.array(transformed_roi_img)\n","\n","cv2_imshow(transformed_roi)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dTl85CVFnOZF"},"outputs":[],"source":["# Transformed binary mask\n","image_mask = cv2.cvtColor(transformed_roi, cv2.COLOR_BGR2GRAY)\n","_, image_mask = cv2.threshold(image_mask, 1, 255, cv2.THRESH_BINARY)\n","\n","masked_roi = cv2.bitwise_and(transformed_roi, transformed_roi, mask=image_mask)\n","mask_inv = cv2.bitwise_not(image_mask)\n","masked_original = cv2.bitwise_and(im, im, mask=mask_inv)\n","\n","combined_image = cv2.add(masked_original, masked_roi)\n","cv2_imshow(combined_image)"]}],"metadata":{"colab":{"provenance":[{"file_id":"1YrkoRgXM9RpekcaUKZA_2AFEYPPNggQQ","timestamp":1714534527171}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
